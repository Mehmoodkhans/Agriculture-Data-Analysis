{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df928755-8b63-4781-ab48-e1cedc8fd818",
   "metadata": {},
   "source": [
    "## 1. Introduction\r\n",
    "\r\n",
    "In this analysis, I explore the factors influencing agricultural crop yields, focusing on key variables such as annual rainfall, temperature fluctuations, and pesticide usage. By leveraging machine learning techniques, I aim to predict future crop yields based on these critical environmental and agricultural factors.\r\n",
    "\r\n",
    "The dataset utilized in this study is sourced from reputable organizations such as the Food and Agriculture Organization (FAO) and the World Data Bank, ensuring the accuracy and relevance of the data. Yield measurements are provided in hectograms per hectare, offering a precise metric for assessing crop productivity.\r\n",
    "\r\n",
    "Through this analysis, I strive to uncover insights that can support agricultural planning and help forecast future trends in crop production.\r\n",
    "\r\n",
    "*Author: Mehmoo Ahmed*\r\n",
    "y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc1632-882f-4230-8052-5354726e9914",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f9491d-a127-471a-8e96-3f904067c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93052d5d-713a-4905-b181-db4d7d67f36e",
   "metadata": {},
   "source": [
    "#### 2. Data Loading and Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592d99e-7e97-4459-9410-58955f6e01c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Agri_data/yield.csv')\n",
    "df_pe = pd.read_csv('Agri_data/pesticides.csv')\n",
    "df_rf = pd.read_csv('Agri_data/rainfall.csv')\n",
    "df_tp = pd.read_csv('Agri_data/temp.csv')\n",
    "df2 = pd.read_csv('Agri_data/yield_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df966b44-409b-4395-99fd-b247acaf10d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.info())\n",
    "print(df_pe.info())\n",
    "print(df_rf.info())\n",
    "print(df_tp.info())\n",
    "print(df2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d739cb8-8e47-46cf-b04d-7e5a3264f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53e7c1-74a8-4b33-a1d4-ec6efe591c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique areas in both dataframes\n",
    "print(\"Unique areas in df1:\", df1['Area'].unique())\n",
    "print(\"Unique areas in df2:\", df2['Area'].unique())\n",
    "\n",
    "# Check the common areas\n",
    "common_areas = set(df1['Area']).intersection(set(df2['Area']))\n",
    "print(f\"Common areas: {len(common_areas)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d180bc-ab1e-4e71-8d5b-2da11ae88f14",
   "metadata": {},
   "source": [
    "#### Merging df1 & df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adfe0f4-a270-43f4-940f-d4911d139698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge using multiple columns: 'Area', 'Item', and 'Year'\n",
    "merged_df = pd.merge(df1, df2, on=['Area', 'Item', 'Year'], how='inner')\n",
    "\n",
    "# Check the resulting shape of the merged dataframe\n",
    "print(merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966742ce-33ef-471c-adb5-04ccd430cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b61fc-8c4f-4fc2-9970-e241de579b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Rename the 'country' column in df_tp to 'Area' for consistency\n",
    "df_tp.rename(columns={'country': 'Area'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc08d6f-61c0-4f69-9476-876ec807a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc46422-40da-48ab-80c5-f1d1248bf5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Rename the 'year' column in df_tp to 'Year' for consistency\n",
    "df_tp.rename(columns={'year': 'Year'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2580b4-7557-4ae2-9e1e-77d3fb216661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3:Clean up column names by stripping any leading/trailing spaces\n",
    "df_pe.columns = df_pe.columns.str.strip()\n",
    "df_rf.columns = df_rf.columns.str.strip()\n",
    "df_tp.columns = df_tp.columns.str.strip()\n",
    "\n",
    "# Check again after cleaning the column names\n",
    "print(\"df_pe columns after cleaning:\", df_pe.columns)\n",
    "print(\"df_rf columns after cleaning:\", df_rf.columns)\n",
    "print(\"df_tp columns after cleaning:\", df_tp.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab2173-c8f2-43a8-995f-b54087186870",
   "metadata": {},
   "source": [
    "#### Merge 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c06683-40fb-4935-9cf7-e1d93c95eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Merge df_pe and df_rf on 'Area' and 'Year'\n",
    "df_merged = pd.merge(df_pe, df_rf, on=['Area', 'Year'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375201f-bf33-4ac1-a50c-40be50608dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ff470b-600e-4bfc-81fd-f4d99048b155",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ecbde-529b-42f7-8229-1597506dff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae03a439-44f7-455d-8ea9-8bf057b52804",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a069c-6921-45fb-a8a6-f697dd5cb51d",
   "metadata": {},
   "source": [
    "#### Merge 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6795c5-bed9-4ba2-9966-508b8ed13045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_tp with df_merged on 'Area' and 'Year'\n",
    "final_merged_df = pd.merge(df_merged, df_tp, left_on=['Area', 'Year'], right_on=['Area', 'Year'], how='inner')\n",
    "\n",
    "# Check the shape and info of the final merged dataframe\n",
    "print(final_merged_df.shape)\n",
    "print(final_merged_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833cb8e-d2ba-4e00-a2cd-634da5d26583",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc8bab-35f2-4241-8971-45a060117ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df.average_rain_fall_mm_per_year.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9a15f-4b84-44ec-9e5e-d9c4ae98594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df['average_rain_fall_mm_per_year'] = pd.to_numeric(\n",
    "    final_merged_df['average_rain_fall_mm_per_year'], errors='coerce'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e65067-1a73-4f37-b55f-230ef8e48957",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b481ce6-4cc9-4343-8464-bb7fcd77bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many common Area values\n",
    "print(\"Common Areas:\", len(set(merged_df['Area']) & set(final_merged_df['Area'])))\n",
    "\n",
    "# Check how many common Items\n",
    "print(\"Common Items:\", len(set(merged_df['Item']) & set(final_merged_df['Item'])))\n",
    "\n",
    "# Check how many common Years\n",
    "print(\"Common Years:\", len(set(merged_df['Year']) & set(final_merged_df['Year'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eab243-a05b-4e17-b473-45eab296cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Items in merged_df:\", merged_df['Item'].unique()[:10])\n",
    "print(\"Items in final_merged_df:\", final_merged_df['Item'].unique()[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff6927f-f2e1-4182-bc84-d826d813610b",
   "metadata": {},
   "source": [
    "##### Reorganizing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b9d9d-4d5a-42bf-b72f-b00a2cd9e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = final_merged_df[['Area', 'Year', 'average_rain_fall_mm_per_year', 'avg_temp']].drop_duplicates()\n",
    "print(clean_df.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1a59f7-0f76-4315-87a9-991afc1eb997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(merged_df, clean_df, on=['Area', 'Year'], how='left')\n",
    "print(df.shape)  # Should be ~28,000 (same as merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152b56a-d611-493b-8ae0-d160f49fb685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58360063-c3e0-4549-bb8e-fcbbe03cdc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(df['average_rain_fall_mm_per_year_x'].equals(df['average_rain_fall_mm_per_year_y']))\n",
    "print(df['avg_temp_x'].equals(df['avg_temp_y']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12ef65-5a2b-4968-980e-fa511e1e2a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('average_rain_fall_mm_per_year_y', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a9519-0f59-4776-8393-deb7f3cc9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['avg_temp_x', 'avg_temp_y']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05187e-f861-480c-8f05-2fc6c967ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('avg_temp_x', axis=1)\n",
    "df = df.rename(columns={'avg_temp_y': 'avg_temp'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d7693-6adb-4222-b081-a74c8046cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e1f1c-c1cb-4171-8d46-83f40c47bf90",
   "metadata": {},
   "source": [
    "### Creating Reference Column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8918de2-f457-4f76-a23d-c12b88eaa001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reference column combining 'Area', 'Item', and 'Year'\n",
    "df['Region_Item_Year'] = df['Area'] + '_' + df['Item'] + '_' + df['Year'].astype(str)\n",
    "\n",
    "# Display the first few rows to ensure it looks correct\n",
    "print(df[['Area', 'Item', 'Year', 'Region_Item_Year']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18be3e-7979-48ae-b22a-92e9d8ceeb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Value'] == df['hg/ha_yield']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d8337-9481-4929-93c0-652f3b49e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Domain Code check:\", df.groupby('Domain Code')['Domain'].nunique().max())\n",
    "print(\"Area Code check:\", df.groupby('Area Code')['Area'].nunique().max())\n",
    "print(\"Element Code check:\", df.groupby('Element Code')['Element'].nunique().max())\n",
    "print(\"Item Code check:\", df.groupby('Item Code')['Item'].nunique().max())\n",
    "print(\"Year Code check:\", df.groupby('Year Code')['Year'].nunique().max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376d85a-bea7-48eb-809e-ca448114b174",
   "metadata": {},
   "source": [
    "#### Dropping Redundant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e468d174-5e42-4fa1-89cb-1d62e612e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Drop redundant object columns (keeping only code columns)\n",
    "columns_to_drop = ['Value','Domain', 'Area', 'Element', 'Item', 'Unit','Year']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Step 2: Convert code columns to 'category' dtype\n",
    "category_cols = ['Domain Code', 'Area Code', 'Element Code', 'Item Code', 'Year Code']\n",
    "df[category_cols] = df[category_cols].astype('category')\n",
    "\n",
    "# Step 3: Confirm dtype changes and resulting shape\n",
    "print(\"\\n✅ Columns dropped:\", columns_to_drop)\n",
    "print(\"\\n✅ Category conversion applied to:\", category_cols)\n",
    "print(\"\\n🧾 Final DataFrame info:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1473299e-fd1f-42a5-80a0-f375c1afaa1b",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a56ffd-8e97-4da9-b4b6-57b3161118e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical columns (if using label encoding)\n",
    "le = LabelEncoder()\n",
    "df['Domain Code'] = le.fit_transform(df['Domain Code'])\n",
    "df['Area Code'] = le.fit_transform(df['Area Code'])\n",
    "df['Element Code'] = le.fit_transform(df['Element Code'])\n",
    "df['Item Code'] = le.fit_transform(df['Item Code'])\n",
    "df['Year Code'] = le.fit_transform(df['Year Code'])\n",
    "\n",
    "# Select features and target variable\n",
    "X = df.drop(columns=['hg/ha_yield','Region_Item_Year'])  # Or 'hg/ha_yield' if you're predicting yield\n",
    "y = df['hg/ha_yield']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3c140-622b-4a80-82f2-0e986132c17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ced0759-2ede-4b21-b475-8d8eb65e7010",
   "metadata": {},
   "source": [
    "### Modeling \n",
    "- LightGBM\n",
    "- Random Forest\n",
    "- \n",
    "CatBoot\n",
    "- \r\n",
    "XGoostoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ceec7-0bbb-44e2-8ebc-e9aa27bb6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the actual categorical column in your dataset\n",
    "categorical_columns = ['Domain Code', 'Area Code', 'Element Code', 'Item Code', 'Year Code']\n",
    "\n",
    "# Convert categorical columns to category dtype for models that support it\n",
    "X_train[categorical_columns] = X_train[categorical_columns].astype('category')\n",
    "X_test[categorical_columns] = X_test[categorical_columns].astype('category')\n",
    "\n",
    "# Initialize all models\n",
    "lgb_model = LGBMRegressor(random_state=42)\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "catboost_model = CatBoostRegressor(random_state=42, verbose=0)\n",
    "xgb_model = XGBRegressor(random_state=42, enable_categorical=True)\n",
    "\n",
    "# Train all models\n",
    "lgb_model.fit(X_train, y_train)  # LightGBM\n",
    "rf_model.fit(X_train, y_train)   # Random Forest (assumes pre-encoded or category-converted)\n",
    "catboost_model.fit(X_train, y_train, cat_features=categorical_columns)  # CatBoost\n",
    "xgb_model.fit(X_train, y_train)  # XGBoost\n",
    "\n",
    "# Make predictions\n",
    "lgb_preds = lgb_model.predict(X_test)\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "catboost_preds = catboost_model.predict(X_test)\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate all models\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{name} RMSE: {rmse:.4f}, MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "\n",
    "evaluate_model(\"LightGBM\", y_test, lgb_preds)\n",
    "evaluate_model(\"Random Forest\", y_test, rf_preds)\n",
    "evaluate_model(\"CatBoost\", y_test, catboost_preds)\n",
    "evaluate_model(\"XGBoost\", y_test, xgb_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854c231-07a4-4bda-b4ee-e2c9c31ea28d",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7357b4a-f268-4d52-8383-60fea93cd4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CatBoost Feature Importance\n",
    "catboost_importance = catboost_model.get_feature_importance()\n",
    "catboost_features = X_train.columns\n",
    "catboost_importance_dict = dict(zip(catboost_features, catboost_importance))\n",
    "\n",
    "# 2. LightGBM Feature Importance\n",
    "lgb_importance = lgb_model.booster_.feature_importance()\n",
    "lgb_importance_dict = dict(zip(X_train.columns, lgb_importance))\n",
    "\n",
    "# 3. XGBoost Feature Importance\n",
    "xgb_importance_raw = xgb_model.get_booster().get_score(importance_type='weight')\n",
    "# Ensure all features are accounted for (including missing ones in XGBoost output)\n",
    "xgb_importance_dict = {feature: xgb_importance_raw.get(feature, 0) for feature in X_train.columns}\n",
    "\n",
    "# 4. Random Forest Feature Importance\n",
    "rf_importance = rf_model.feature_importances_\n",
    "rf_importance_dict = dict(zip(X_train.columns, rf_importance))\n",
    "\n",
    "# Combine all into a DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'CatBoost': [catboost_importance_dict.get(f, 0) for f in X_train.columns],\n",
    "    'LightGBM': [lgb_importance_dict.get(f, 0) for f in X_train.columns],\n",
    "    'XGBoost': [xgb_importance_dict.get(f, 0) for f in X_train.columns],\n",
    "    'RandomForest': [rf_importance_dict.get(f, 0) for f in X_train.columns],\n",
    "})\n",
    "\n",
    "# sort by average importance across models (or by a specific model)\n",
    "importance_df['Average'] = importance_df[['CatBoost', 'LightGBM', 'XGBoost', 'RandomForest']].mean(axis=1)\n",
    "importance_df_sorted = importance_df.sort_values(by='Average', ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(importance_df_sorted.drop(columns='Average'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4136c12f-fb51-4787-b665-bdd9c2afd598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make normalize as percentage of total\n",
    "percentage_df = importance_df.copy()\n",
    "\n",
    "for model in ['CatBoost', 'LightGBM', 'XGBoost', 'RandomForest']:\n",
    "    total = importance_df[model].sum()\n",
    "    percentage_df[model] = (importance_df[model] / total) * 100\n",
    "\n",
    "#  sort by average importance\n",
    "percentage_df['Average'] = percentage_df[['CatBoost', 'LightGBM', 'XGBoost', 'RandomForest']].mean(axis=1)\n",
    "percentage_df_sorted = percentage_df.sort_values(by='Average', ascending=False)\n",
    "\n",
    "# Average \n",
    "print(percentage_df_sorted.drop(columns='Average').round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2913cf1f-5266-42a8-af48-d91934f57a8b",
   "metadata": {},
   "source": [
    "### Vizualization Feature_Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ff181-6646-41d1-b695-8fbe5506ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature names as index for cleaner axis labeling\n",
    "viz_df = percentage_df_sorted.drop(columns='Average').set_index('Feature')\n",
    "\n",
    "# Apply log scaling to improve visibility of lower values\n",
    "log_viz_df = np.log1p(viz_df)  # log1p ensures zero values stay valid\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(log_viz_df, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Log(Importance + 1) (%)'}, linewidths=0.5)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(\"Feature Importances Across Models (Log-Scaled)\", fontsize=16)\n",
    "plt.xlabel(\"Model\", fontsize=14)\n",
    "plt.ylabel(\"Feature\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a33b28-40b1-448d-8f78-78ab9bbd982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "viz_df_reset = viz_df.reset_index().melt(id_vars='Feature', var_name='Model', value_name='Importance')\n",
    "\n",
    "# Flip roles: Feature on x-axis, Model on y-axis\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(data=viz_df_reset, x='Feature', y='Importance', hue='Model')\n",
    "\n",
    "# Customize\n",
    "plt.title(\"Feature Importance across Models\", fontsize=16)\n",
    "plt.xlabel(\"Feature\", fontsize=12)\n",
    "plt.ylabel(\"Importance (%)\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Model', loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9c401-5988-43d2-aa2d-9c8d374146b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models list and features\n",
    "models = viz_df.columns.tolist()\n",
    "features = viz_df.index.tolist()\n",
    "bar_colors = ['skyblue', 'lightgreen', 'salmon', 'plum']  # distinct but soft\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(models), figsize=(20, 7), sharey=True)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    axes[i].bar(features, viz_df[model], color=bar_colors[i % len(bar_colors)])\n",
    "    axes[i].set_title(model, fontsize=16, fontweight='bold')\n",
    "    axes[i].set_xticks(range(len(features)))\n",
    "    axes[i].set_xticklabels(features, rotation=45, ha='right', fontsize=10)\n",
    "    axes[i].set_xlabel(\"Feature\", fontsize=12)\n",
    "    axes[i].grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Importance (%)\", fontsize=12)\n",
    "\n",
    "# Main title\n",
    "fig.suptitle(\"Feature Importance Across Models\", fontsize=22, fontweight='bold')\n",
    "\n",
    "# Layout adjustments\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.92])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892a9f1-0074-4b10-b13b-f333f0c1af5e",
   "metadata": {},
   "source": [
    "## Cross Validation \n",
    "- LightGBM , Random Forest, CatBoost & XGBooost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d8f6e-0264-47b4-9de0-1d6db889f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your categorical features\n",
    "cat_features = ['Domain Code', 'Area Code', 'Element Code', 'Item Code', 'Year Code']  # Add any other categorical column names here\n",
    "\n",
    "# Fit the models\n",
    "catboost_model.fit(X_train, y_train, cat_features=cat_features)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c1aa05-c9f1-4423-a4f1-a84d146b1681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_rmse_r2(model, X, y, model_name):\n",
    "    # from sklearn.metrics import mean_squared_error, r2_score\n",
    "    # from sklearn.model_selection import KFold\n",
    "  \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = []\n",
    "    r2_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "        X_train_fold = X.iloc[train_idx].copy()\n",
    "        X_val_fold = X.iloc[val_idx].copy()\n",
    "        y_train_fold = y.iloc[train_idx]\n",
    "        y_val_fold = y.iloc[val_idx]\n",
    "\n",
    "        # Ensure all features are numeric\n",
    "        X_train_fold = X_train_fold.apply(pd.to_numeric, errors='coerce')\n",
    "        X_val_fold = X_val_fold.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        # Debugging: Check NaN counts\n",
    "        print(f\"Fold {fold} - NaN in train features:\", X_train_fold.isna().sum().sum())\n",
    "        print(f\"Fold {fold} - NaN in val features:\", X_val_fold.isna().sum().sum())\n",
    "\n",
    "        # Drop rows with NaN values (or use imputation if preferred)\n",
    "        X_train_fold = X_train_fold.dropna()\n",
    "        y_train_fold = y_train_fold[X_train_fold.index]\n",
    "        X_val_fold = X_val_fold.dropna()\n",
    "        y_val_fold = y_val_fold[X_val_fold.index]\n",
    "\n",
    "        # Train model and predict\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        preds = model.predict(X_val_fold)\n",
    "\n",
    "        # Evaluate model\n",
    "        rmse = np.sqrt(mean_squared_error(y_val_fold, preds))\n",
    "        r2 = r2_score(y_val_fold, preds)\n",
    "\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"{model_name} RMSE CV Scores:\", np.round(rmse_scores, 4))\n",
    "    print(f\"{model_name} Mean RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}\")\n",
    "    print(f\"{model_name} R² CV Scores:\", np.round(r2_scores, 4))\n",
    "    print(f\"{model_name} Mean R²: {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ddaf1-3fdc-4406-bcd2-0ab05160d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get RMSE and R² from cross-validation for all models\n",
    "def get_cv_rmse_r2_all_models(X, y, cat_features=None):\n",
    "    models = {\n",
    "        \"Random Forest\": RandomForestRegressor(),\n",
    "        \"XGBoost\": xgb.XGBRegressor(),\n",
    "        \"LightGBM\": lgb.LGBMRegressor(),\n",
    "        \"CatBoost\": CatBoostRegressor(random_state=42, verbose=0)\n",
    "    }\n",
    "    \n",
    "    # Store the results for each model in a dictionary\n",
    "    results_dict = {}\n",
    "\n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        rmse_scores = []\n",
    "        r2_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "            X_train_fold = X.iloc[train_idx].copy()\n",
    "            X_val_fold = X.iloc[val_idx].copy()\n",
    "            y_train_fold = y.iloc[train_idx]\n",
    "            y_val_fold = y.iloc[val_idx]\n",
    "\n",
    "            # Ensure all features are numeric (except for CatBoost which uses Pools)\n",
    "            X_train_fold = X_train_fold.apply(pd.to_numeric, errors='coerce')\n",
    "            X_val_fold = X_val_fold.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Drop rows with NaN values\n",
    "            X_train_fold, y_train_fold = X_train_fold.align(y_train_fold, join='inner', axis=0)\n",
    "            X_val_fold, y_val_fold = X_val_fold.align(y_val_fold, join='inner', axis=0)\n",
    "\n",
    "            if X_train_fold.empty or X_val_fold.empty:\n",
    "                print(f\"Skipping Fold {fold} due to empty training or validation data.\")\n",
    "                continue\n",
    "\n",
    "            # Handle model fitting based on whether it's CatBoost or other models\n",
    "            if model_name == \"CatBoost\":\n",
    "                train_pool = Pool(X_train_fold, y_train_fold, cat_features=cat_features)\n",
    "                val_pool = Pool(X_val_fold, y_val_fold, cat_features=cat_features)\n",
    "                model.fit(train_pool, verbose=0)\n",
    "                preds = model.predict(val_pool)\n",
    "            else:\n",
    "                model.fit(X_train_fold, y_train_fold)\n",
    "                preds = model.predict(X_val_fold)\n",
    "\n",
    "            # Evaluate model\n",
    "            rmse = np.sqrt(mean_squared_error(y_val_fold, preds))\n",
    "            r2 = r2_score(y_val_fold, preds)\n",
    "\n",
    "            rmse_scores.append(rmse)\n",
    "            r2_scores.append(r2)\n",
    "        \n",
    "        # Calculate mean and standard deviation for the model\n",
    "        mean_rmse = np.mean(rmse_scores)\n",
    "        std_rmse = np.std(rmse_scores)\n",
    "        mean_r2 = np.mean(r2_scores)\n",
    "        std_r2 = np.std(r2_scores)\n",
    "\n",
    "        # Store the results in the dictionary\n",
    "        results_dict[model_name] = {\n",
    "            'RMSE Scores': np.round(rmse_scores, 4),\n",
    "            'Mean RMSE': f\"{mean_rmse:.4f} ± {std_rmse:.4f}\",\n",
    "            'R² Scores': np.round(r2_scores, 4),\n",
    "            'Mean R²': f\"{mean_r2:.4f} ± {std_r2:.4f}\"\n",
    "        }\n",
    "    \n",
    "    # Convert the results dictionary into a DataFrame for better visualization\n",
    "    results_df = pd.DataFrame(results_dict).T  # Transpose to make models rows\n",
    "    return results_df\n",
    "\n",
    "# Example usage:\n",
    "# Define categorical features for CatBoost (you can adjust it to your needs)\n",
    "cat_features = ['Domain Code', 'Area Code', 'Element Code', 'Item Code', 'Year Code']  # Replace with your real categorical columns\n",
    "\n",
    "# Get results for all models in one go\n",
    "results_df = get_cv_rmse_r2_all_models(X_train, y_train, cat_features)\n",
    "\n",
    "# Print all results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd2f8d-7e12-4c2e-90c3-805537eb9a16",
   "metadata": {},
   "source": [
    "#### Vizualization CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2924c59-1557-4213-a6ef-d8a64eafc2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_scores(results_df):\n",
    "    rmse_data = []\n",
    "    r2_data = []\n",
    "\n",
    "    for model in results_df.index:\n",
    "        rmse_scores = results_df.loc[model, 'RMSE Scores']\n",
    "        r2_scores = results_df.loc[model, 'R² Scores']\n",
    "        for i, score in enumerate(rmse_scores):\n",
    "            rmse_data.append({'Model': model, 'Fold': i+1, 'RMSE': score})\n",
    "        for i, score in enumerate(r2_scores):\n",
    "            r2_data.append({'Model': model, 'Fold': i+1, 'R²': score})\n",
    "\n",
    "    rmse_df = pd.DataFrame(rmse_data)\n",
    "    r2_df = pd.DataFrame(r2_data)\n",
    "\n",
    "    # Plotting\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(data=rmse_df, x='Model', y='RMSE', palette='Set2')\n",
    "    sns.stripplot(data=rmse_df, x='Model', y='RMSE', color='black', alpha=0.6, jitter=0.1, size=5)\n",
    "    plt.title(\"Cross-Validated RMSE per Model\", fontsize=14)\n",
    "    plt.xticks(rotation=15)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(data=r2_df, x='Model', y='R²', palette='Set3')\n",
    "    sns.stripplot(data=r2_df, x='Model', y='R²', color='black', alpha=0.6, jitter=0.1, size=5)\n",
    "    plt.title(\"Cross-Validated R² per Model\", fontsize=14)\n",
    "    plt.xticks(rotation=15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return rmse_df, r2_df  # 👈 return the DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e190df-84d8-4c78-9d91-ff40e20e8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_df, r2_df = plot_cv_scores(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ecd75-a6f1-4ceb-94ec-b7ca31a281a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.swarmplot(data=rmse_df, x='Model', y='RMSE', palette='Set1', size=6)\n",
    "plt.title(\"Cross-Validated RMSE (Swarm Plot)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.swarmplot(data=r2_df, x='Model', y='R²', palette='Set2', size=6)\n",
    "plt.title(\"Cross-Validated R² (Swarm Plot)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5667e0b-109c-445e-98b1-a3677ca408ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by and calculate mean and std\n",
    "rmse_summary = rmse_df.groupby(\"Model\")[\"RMSE\"].agg(['mean', 'std']).reset_index()\n",
    "r2_summary = r2_df.groupby(\"Model\")[\"R²\"].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Set visual style\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# RMSE Plot\n",
    "sns.barplot(data=rmse_summary, x='Model', y='mean', ax=axes[0], palette='coolwarm')\n",
    "axes[0].errorbar(x=range(len(rmse_summary)), y=rmse_summary['mean'], yerr=rmse_summary['std'], fmt='none', c='black', capsize=5)\n",
    "axes[0].set_title(\"Mean RMSE with Std Dev\")\n",
    "axes[0].set_ylabel(\"RMSE\")\n",
    "axes[0].set_xlabel(\"Model\")\n",
    "\n",
    "# R² Plot\n",
    "sns.barplot(data=r2_summary, x='Model', y='mean', ax=axes[1], palette='viridis')\n",
    "axes[1].errorbar(x=range(len(r2_summary)), y=r2_summary['mean'], yerr=r2_summary['std'], fmt='none', c='black', capsize=5)\n",
    "axes[1].set_title(\"Mean R² with Std Dev\")\n",
    "axes[1].set_ylabel(\"R²\")\n",
    "axes[1].set_xlabel(\"Model\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b26d44-4dae-4cd1-a426-23283678d93c",
   "metadata": {},
   "source": [
    "## 📊 Final Summary and Conclusions\r\n",
    "\r\n",
    "### 📌 Project Objective\r\n",
    "The goal of this analysis is to explore factors influencing agricultural crop yields — including rainfall, temperature, and pesticide usage — and to develop machine learning models that can predict future yields. This study utilizes data from the FAO (Food and Agriculture Organization) and the World Data Bank.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 🔍 Key Findings\r\n",
    "\r\n",
    "- **Best Performing Model**: **Random Forest Regressor**\r\n",
    "- **Most Important Feature Across Models**: `Item Code` followed by `Area Code`\r\n",
    "- All models achieved **high R² values**, indicating excellent predictive performance.\r\n",
    "- Cross-validation confirmed that **Random Forest consistently outperforms** the other models in terms of RMSE and stability.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 📈 Model Performance Comparison (Test Set)\r\n",
    "\r\n",
    "| Model         | RMSE       | MSE           | R² Score |\r\n",
    "|---------------|------------|----------------|----------|\r\n",
    "| LightGBM      | 6362.36    | 40,479,669.76  | 0.9950   |\r\n",
    "| Random Forest | 3914.36    | 15,322,231.10  | 0.9981   |\r\n",
    "| CatBoost      | 7645.58    | 58,454,874.06  | 0.9927   |\r\n",
    "| XGBoost       | 4294.43    | 18,442,140.75  | 0.9977   |\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 📌 Feature Importance (Top Features)\r\n",
    "\r\n",
    "| Feature                         | CatBoost | LightGBM | XGBoost | RandomForest |\r\n",
    "|---------------------------------|----------|----------|---------|--------------|\r\n",
    "| `Item Code`                     | 67.55    | 23.43    | 26.47   | 75.15        |\r\n",
    "| `Area Code`                     | 6.42     | 35.50    | 35.49   | 7.12         |\r\n",
    "| `Year Code`                     | 3.41     | 19.43    | 29.24   | 3.09         |\r\n",
    "| `pesticides_tonnes`            | 5.91     | 12.53    | 6.23    | 3.69         |\r\n",
    "| `average_rain_fall_mm_per_year_x` | 10.22 | 5.03     | 0.00    | 5.54         |\r\n",
    "| `avg_temp`                      | 6.48     | 4.07     | 2.57    | 5.41         |\r\n",
    "\r\n",
    "> Note: `Domain Code` and `Element Code` were found to be non-informative (0.00 importance in all models).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 🔁 Cross-Validation Summary (5-Fold)\r\n",
    "\r\n",
    "| Model         | Mean RMSE ± StdDev | Mean R² ± StdDev  |\r\n",
    "|---------------|--------------------|--------------------|\r\n",
    "| Random Forest | 4316.97 ± 286.65   | 0.9977 ± 0.0003     |\r\n",
    "| XGBoost       | 7305.47 ± 303.50   | 0.9933 ± 0.0005     |\r\n",
    "| LightGBM      | 10044.71 ± 314.38  | 0.9874 ± 0.0007     |\r\n",
    "| CatBoost      | 8148.94 ± 189.21   | 0.9917 ± 0.0004     |\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### ✅ Final Recommendation\r\n",
    "\r\n",
    "Based on performance metrics, cross-validation results, and feature importance analysis, **Random Forest Regressor** is the most reliable model for predicting crop yields in this dataset. It offers the **best balance between accuracy, stability, and interpretability**.\r\n",
    "\r\n",
    "For future work:\r\n",
    "- Explore time-series modeling using temporal trends.\r\n",
    "- Consider adding soil health, fertilizer usage, or satellite data for enhanced accuracy.\r\n",
    "- Deploy the Random Forest model in a simple web interface or API for real-time predictions.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "👨‍💻 *Report prepared by: Mehmood Ahmed*\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea1fef-fc7d-40d4-8694-91201965805f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
